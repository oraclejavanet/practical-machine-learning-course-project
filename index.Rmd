---
title: "Practical Machine Learning Course Project"
author: "Jeffrey M. Hunter"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: cosmo
    keep_md: no
    df_print: paged
    css: css/custom.css
  pdf_document:
    toc: yes
    df_print: kable
    number_sections: false
    fig_caption: yes
    highlight: tango
    dev: pdf
  word_document:
    toc: yes
    df_print: paged
    keep_md: no
---

## Synopsis

This report contains research that was conducted for the Practical Machine
Learning course as part of the Data Science Specialization offered through
Coursera from Johns Hopkins University. This writeup was built in RStudio
using the knitr function to publish the final report in HTML format.

The source code for this project can be found on
GitHub: <a target="_blank" href="https://github.com/oraclejavanet/practical-machine-learning-course-project">Practical Machine Learning Course Project</a>

## Introduction

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now
possible to collect a large amount of data about personal activity relatively
inexpensively. These type of devices are part of the quantified self movement â€“
a group of enthusiasts who take measurements about themselves regularly to
improve their health, to find patterns in their behavior, or because they are
tech geeks. One thing that people regularly do is quantify how much of a
particular activity they do, but they rarely quantify how well they do it.

The goal for this assignment is to analyze the *Weight Lifting Exercise*
dataset and develop a machine learning algorithm using biometric data to predict
the manner in which 6 participants performed a particular dumbbell exercise.
This is the "classe" variable in the training set.

The biometric data was collected from accelerometers on the belt, forearm, arm,
and dumbbell of the 6 participants. The participants were asked to perform
barbell lifts correctly and incorrectly in 5 different ways.

> For more information about the dataset used for this analysis, see section
<a target="_blank" href="http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises">Weight Lifting Exercises Dataset</a> from the Human Activity Recognition (HAR) project website.

The resulting prediction model will also serve as the basis for the
"Course Project Prediction Quiz Portion" of this assignment where the machine
learning algorithm will be applied to 20 test cases available in the test data.
The predictions will submitted in the appropriate format for automated grading.

## Environment Setup

Prepare the session by loading all necessary packages and clearing the global
workspace (including hidden objects).

```{r load-packages, message = FALSE, echo = TRUE}
library(knitr)
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(e1071)
library(randomForest)
library(gbm)
library(parallel)
library(doParallel)
rm(list = ls(all.names = TRUE))
setwd("~/repos/coursera/data-science-specialization-github-assignments/practical-machine-learning-course-project")
```

```{r setup, include = FALSE}
# set knitr options
knitr::opts_chunk$set(echo = TRUE, fig.path = 'figures/')

# free up memory and display statistics on free memory
gc()

# disable scientific notation for numbers
options(scipen = 1)

# detect OS
switch(Sys.info()[['sysname']],
    Windows = {os = "Microsoft Windows"},
    Linux = {os = "Linux"},
    Darwin = {os = "macOS"})

# knit hook to allow partial output from a code chunk
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options)) # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines) == 1) { # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```

## Prepare the Data

### Load the Data

```{r load-data, echo = TRUE}
trainURL <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
validationURL  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

trainDataFile <- "data/pml-training.csv"
validationDataFile <- "data/pml-testing.csv"

if (!file.exists('data')) {
    dir.create('data')
}
if (!file.exists(trainDataFile)) {
    download.file(url = trainURL, destfile = trainDataFile)
}
if (!file.exists(validationDataFile)) {
    download.file(url = validationURL, destfile = validationDataFile)
}

trainData <- read.csv(trainDataFile, sep = ",", header = TRUE)
validationData <- read.csv(validationDataFile, sep = ",", header = TRUE)

stopifnot(file.size(trainDataFile) == 12202745)
stopifnot(file.size(validationDataFile) == 15113)
```

```{r dataset-dimensions, echo = TRUE}
dim(trainData)
dim(validationData)
```

The training dataset contains `r dim(trainData)[1]` observations and
`r dim(trainData)[2]` variables while the testing dataset (used for the
prediction quiz portion of the assignment) contains `r dim(validationData)[1]`
observations and `r dim(validationData)[2]` variables.

### Clean the Data

An initial review of both datasets revealed a larger number of missing values
as well as columns not relevant for prediction. Reduce the number of features
to only include data columns that make sense for prediction.

```{r clean-data, echo = TRUE}
# remove variables with 'Nearly Zero Variance'
nzv <- nearZeroVar(trainData)
trainData  <- trainData[, -nzv]
validationData  <- validationData[, -nzv]

# remove variables that are mostly NA
mostlyNA <- sapply(trainData, function(x) mean(is.na(x))) > 0.95
trainData <- trainData[, mostlyNA == FALSE]
validationData <- validationData[, mostlyNA == FALSE]

# remove first 7 variables (time series or non-numeric data)
trainData <- trainData[, -c(1:7)]
validationData <- validationData[, -c(1:7)]

# determine data variables that will be used to fit models
dataVariables <- names(trainData[, 1:(length(trainData)-1)])
```

After cleaning, the models will be fit using the following
`r length(dataVariables)` variables:

```{r show-model-variables, echo = FALSE}
dataVariables
```

### Partition the Data

Knowing that we will be predicting the "classe" variable as the indicator of the
training outcome, partition the training dataset (`trainData`) into two sets:
60% of the training data for the modeling process and the remaining 40% for the
test set. This will be performed using random subsampling without replacement.
Cross-validation within the training set will be used to improve model fit
followed by an out-of-sample test with the test set.

```{r partition-data, echo = TRUE}
inTrain  <- createDataPartition(trainData$classe, p = 0.6, list = FALSE)
trainSet <- trainData[inTrain, ]
testSet  <- trainData[-inTrain, ]
```

The `validationData` test dataset will only be used for the "Course Project
Prediction Quiz Portion" of this assignment and thus will remain unchanged.

## Exploratory Data Analysis

The 6 young and healthy participants were asked to perform one set of 10
repetitions of the *Unilateral Dumbbell Biceps Curl* in the following 5
different fashions:

* Class A: exactly according to the specification
* Class B: throwing the elbows to the front
* Class C: lifting the dumbbell only halfway
* Class D: lowering the dumbbell only halfway
* Class E: throwing the hips to the front

This is the "classe" variable in the training set and is used as an indicator
of the training outcome. Class A corresponds to the specified (correct)
execution of the exercise, while the other 4 classes correspond to common
mistakes.

The following plot shows the distribution of the classe variable in the training
set.

```{r dist-classe-var-training-set, echo = TRUE}
g <- ggplot(trainSet, aes(classe))
g <- g + geom_bar(fill = rgb(0.2, 0.4, 0.6, 0.8))
g <- g + xlab("Classe Level")
g <- g + ylab("Frequency")
g <- g + theme(plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
               axis.text.x = element_text(hjust = 0.5, vjust = 0.5),
               axis.text.y = element_text(hjust = 0.5, vjust = 0.5))
g <- g + ggtitle("Distribution of the Classe Variable in the Training Set")
print(g)
```

## Prediction Model Building

The following three modeling algorithms will be used in this analysis to
determine which one provides the best out-of-sample accuracy:

* Decision Tree
* Random Forest
* Generalized Boosted Model

Parallel processing will be used to improve efficiency and reduce build time.

At the end of each analysis, a confusion matrix will be shown to better
visualize the accuracy of the predictions.

After applying each model to the test set, the model with the highest accuracy
will be used for the prediction quiz portion of the assignment.

### Cross Validation

3-fold (k-fold) cross-validation will be used within the training set for each
model to tune the amount of bias in the model and improve accuracy.

```{r set-fit-control, echo = TRUE}
# decision tree
fitControlDT <- rpart.control(method = "cv", number = 3, verboseIter = FALSE)

# random forest
fitControlRF <- trainControl(method = "cv", number = 3, verboseIter = FALSE, 
                             allowParallel = TRUE)

# generalized boosted model
fitControlGBM <- trainControl(method = "repeatedcv", number = 3, repeats = 1,
                              verboseIter = FALSE, allowParallel = TRUE)

```

### Decision Tree

Build the model and print the decision tree dentigram.

```{r decision-tree-model-fit, message = FALSE, echo = TRUE, results = 'hold'}
set.seed(660067)
modFitDT <- rpart(as.factor(classe) ~ .,
                  data = trainSet,
                  control = fitControlDT,
                  method = "class")

prp(modFitDT,
    faclen = 0,
    box.palette = "GnBu",
    cex = 0.50,
    legend.x = 0,
    legend.y = 1,
    legend.cex = 1)
```

Validate the Decision Tree model on the test set (`testSet`) to determine how
well it performed and the accuracy of the results.

```{r decision-tree-prediction, echo = TRUE}
predictionDT <- predict(modFitDT, newdata = testSet, type = "class")
confMatrixDT <- confusionMatrix(predictionDT, testSet$classe)
print(confMatrixDT)
```

Plot the matrix results.

```{r decision-tree-matrix-results, echo = TRUE}
g <- ggplot(data = as.data.frame(confMatrixDT$table),
            aes(x = Prediction, y = Reference))
g <- g + geom_tile(aes(fill = Freq), colour = "white")
g <- g + scale_fill_gradient(low = "white", high = "steelblue", name = "Frequency")
g <- g + geom_text(aes(x = Prediction, y = Reference, label = Freq))
g <- g + theme(plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
               axis.text.x = element_text(hjust = 0.5, vjust = 0.5),
               axis.text.y = element_text(hjust = 0.5, vjust = 0.5))
g <- g + ggtitle(paste0("Decision Tree Accuracy ",
                        round(confMatrixDT$overall['Accuracy'], 3) * 100,
                        "%"))
print(g)
```

The results from the confusion matrix for the Decision Tree model show a
predicted accuracy of `r round(confMatrixDT$overall['Accuracy'], 3)` giving an
out-of-sample error rate of `r 1 - round(confMatrixDT$overall['Accuracy'], 3)`
which is considerably high.

### Random Forest

Build the Random Forest model.

```{r random-forest-model-fit, message = FALSE, echo = TRUE, results = 'hold'}
set.seed(660067)
# initiate the cluster, leave 1 core for OS
# NOTE: make certain "127.0.0.1 localhost" exists in /etc/hosts
numCores <- detectCores() - 1
cluster <- makeCluster(numCores)
registerDoParallel(cluster)
timerStart <- Sys.time()
modFitRF <- train(classe ~ .,
                  data = trainSet,
                  method = "rf",
                  trControl = fitControlRF,
                  verbose = FALSE)
timerEnd <- Sys.time()
stopCluster(cluster)
registerDoSEQ()
buildTime = paste(round(timerEnd - timerStart, 2), attr(timerEnd - timerStart, "units"))
```

Build time: `r buildTime` using `r numCores` cores on `r os`.

Review the final model.

```{r random-forest-final-model, message = FALSE, echo = TRUE}
print(modFitRF$finalModel)
```

Validate the Random Forest model on the test set (`testSet`) to determine how
well it performed and the accuracy of the results.

```{r random-forest-prediction, echo = TRUE}
predictionRF <- predict(modFitRF, newdata = testSet)
confMatrixRF <- confusionMatrix(predictionRF, testSet$classe)
print(confMatrixRF)
```

Plot the matrix results.

```{r random-forest-matrix-results, echo = TRUE}
g <- ggplot(data = as.data.frame(confMatrixRF$table),
            aes(x = Prediction, y = Reference))
g <- g + geom_tile(aes(fill = Freq), colour = "white")
g <- g + scale_fill_gradient(low = "white", high = "steelblue", name = "Frequency")
g <- g + geom_text(aes(x = Prediction, y = Reference, label = Freq))
g <- g + theme(plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
               axis.text.x = element_text(hjust = 0.5, vjust = 0.5),
               axis.text.y = element_text(hjust = 0.5, vjust = 0.5))
g <- g + ggtitle(paste0("Random Forest Accuracy ",
                        round(confMatrixRF$overall['Accuracy'], 3) * 100,
                        "%"))
print(g)
```

The results from the confusion matrix for the Random Forest model show a
predicted accuracy of `r round(confMatrixRF$overall['Accuracy'], 3)` giving an
out-of-sample error rate of `r 1 - round(confMatrixRF$overall['Accuracy'], 3)`
which shows that the model produces very accurate predictions.

### Generalized Boosted Model

Build the Generalized Boosted Model, an implementation of extensions to Freund
and Schapire's AdaBoost algorithm and Friedman's gradient boosting machine.

```{r generalized-boosted-model-fit, message = FALSE, echo = TRUE, results = 'hold'}
set.seed(660067)
# initiate the cluster, leave 1 core for OS
# NOTE: make certain "127.0.0.1 localhost" exists in /etc/hosts
numCores <- detectCores() - 1
cluster <- makeCluster(numCores)
registerDoParallel(cluster)
timerStart <- Sys.time()
modFitGBM <- train(classe ~ .,
                   data = trainSet,
                   method = "gbm",
                   trControl = fitControlGBM,
                   verbose = FALSE)
timerEnd <- Sys.time()
stopCluster(cluster)
registerDoSEQ()
buildTime = paste(round(timerEnd - timerStart, 2), attr(timerEnd - timerStart, "units"))
```

Build time: `r buildTime` using `r numCores` cores on `r os`.

Review the final model.

```{r generalized-boosted-final-model, message = FALSE, echo = TRUE}
print(modFitGBM$finalModel)
```

Validate the Generalized Boosted Model on the test set (`testSet`) to determine
how well it performed and the accuracy of the results.

```{r generalized-boosted-prediction, echo = TRUE}
predictionGBM <- predict(modFitGBM, newdata = testSet)
confMatrixGBM <- confusionMatrix(predictionGBM, testSet$classe)
print(confMatrixGBM)
```

Plot the matrix results.

```{r generalized-boosted-matrix-results, echo = TRUE}
g <- ggplot(data = as.data.frame(confMatrixGBM$table),
            aes(x = Prediction, y = Reference))
g <- g + geom_tile(aes(fill = Freq), colour = "white")
g <- g + scale_fill_gradient(low = "white", high = "steelblue", name = "Frequency")
g <- g + geom_text(aes(x = Prediction, y = Reference, label = Freq))
g <- g + theme(plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
               axis.text.x = element_text(hjust = 0.5, vjust = 0.5),
               axis.text.y = element_text(hjust = 0.5, vjust = 0.5))
g <- g + ggtitle(paste0("Generalized Boosted Model Accuracy ",
                        round(confMatrixGBM$overall['Accuracy'], 3) * 100,
                        "%"))
print(g)
```

The results from the confusion matrix for the Generalized Boosted Model show a
predicted accuracy of `r round(confMatrixGBM$overall['Accuracy'], 3)` giving an
out-of-sample error rate of `r 1 - round(confMatrixGBM$overall['Accuracy'], 3)`
which shows that the model produces very accurate predictions.

## Conclusion

The goal for this project was to predict the manner in which a participant
performed a particular dumbbell exercise. Using biometric data from the
Weight Lifting Exercise dataset, we were able to fit three models that yielded
the following accuracy rates:

* Decision Tree : `r round(confMatrixDT$overall['Accuracy'], 3)`
* Random Forest : `r round(confMatrixRF$overall['Accuracy'], 3)`
* Generalized Boosted Model: `r round(confMatrixGBM$overall['Accuracy'], 3)`

The Random Forest model proved to be the most accurate model for predicting
the class of dumbbell exercise. As such, I will use the previously created
Random Forest model to predict the 20 cases for the quiz portion of the
assignment.

```{r random-forest-prediction-quiz, echo = TRUE}
predictionQuiz <- predict(modFitRF, newdata = validationData)
predictionQuiz
```
