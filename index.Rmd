---
title: "Practical Machine Learning Course Project"
author: "Jeffrey M. Hunter"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: cosmo
    keep_md: no
    df_print: paged
    css: css/custom.css
  pdf_document:
    toc: yes
    df_print: kable
    number_sections: false
    fig_caption: yes
    highlight: tango
    dev: pdf
  word_document:
    toc: yes
    df_print: paged
    keep_md: no
---

## Synopsis

This report contains research that was conducted for the Practical Machine
Learning course as part of the Data Science Specialization offered through
Coursera from Johns Hopkins University. This writeup was built in RStudio
using the knitr function to publish the final report in HTML format.

The source code for this project can be found on
GitHub: <a target="_blank" href="https://github.com/oraclejavanet/practical-machine-learning-course-project">Practical Machine Learning Course Project</a>

## Introduction

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now
possible to collect a large amount of data about personal activity relatively
inexpensively. These type of devices are part of the quantified self movement â€“
a group of enthusiasts who take measurements about themselves regularly to
improve their health, to find patterns in their behavior, or because they are
tech geeks. One thing that people regularly do is quantify how much of a
particular activity they do, but they rarely quantify how well they do it.

The goal for this assignment is to analyze the *Weight Lifting Exercise*
dataset and develop a machine learning algorithm using biometric data to predict
the manner in which 6 participants performed a particular dumbbell exercise.
This is the "classe" variable in the training set.

The biometric data was collected from accelerometers on the belt, forearm, arm,
and dumbbell of the 6 participants. The participants were asked to perform
barbell lifts correctly and incorrectly in 5 different ways.

> For more information about the dataset used for this analysis, see section
<a target="_blank" href="http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises">Weight Lifting Exercises Dataset</a> from the Human Activity Recognition (HAR) project website.

The resulting prediction model will also serve as the basis for the
"Course Project Prediction Quiz Portion" of this assignment where the machine
learning algorithm will be applied to 20 test cases available in the test data.
The predictions will submitted in the appropriate format for automated grading.

## Environment Setup

Prepare the session by loading all necessary packages and clearing the global
workspace (including hidden objects).

```{r load-packages, message = FALSE, echo = TRUE}
library(knitr)
library(ggplot2)
library(caret)
library(corrplot)
library(randomForest)
rm(list = ls(all.names = TRUE))
setwd("~/repos/coursera/github-assignments/practical-machine-learning-course-project")
```

```{r setup, include = FALSE}
# set knitr options
knitr::opts_chunk$set(echo = TRUE, fig.path = 'figures/')

# free up memory and display statistics on free memory
gc()

# disable scientific notation for numbers
options(scipen = 1)

# knit hook to allow partial output from a code chunk
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options)) # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines) == 1) { # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```

## Prepare the Data

### Load the Data

```{r load-data, echo = TRUE}
trainURL <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
validationURL  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

trainDataFile <- "data/pml-training.csv"
validationDataFile <- "data/pml-testing.csv"

if (!file.exists('data')) {
    dir.create('data')
}
if (!file.exists(trainDataFile)) {
    download.file(url = trainURL, destfile = trainDataFile)
}
if (!file.exists(validationDataFile)) {
    download.file(url = validationURL, destfile = validationDataFile)
}

trainData <- read.csv(trainDataFile, sep = ",", header = TRUE)
validationData <- read.csv(validationDataFile, sep = ",", header = TRUE)

stopifnot(file.size(trainDataFile) == 12202745)
stopifnot(file.size(validationDataFile) == 15113)
```

```{r dataset-dimensions, echo = TRUE}
dim(trainData)
dim(validationData)
```

The training dataset contains `r dim(trainData)[1]` observations and
`r dim(trainData)[2]` variables while the testing dataset (used for the
prediction quiz portion of the assignment) contains `r dim(validationData)[1]`
observations and `r dim(validationData)[2]` variables.

### Clean the Data

An initial review of both datasets revealed a larger number of missing values
as well as columns not relevant for prediction. Reduce the number of features
to only include data columns that make sense for prediction.

```{r clean-data, echo = TRUE}
# remove variables with 'Nearly Zero Variance'
NZV <- nearZeroVar(trainData)
trainData  <- trainData[, -NZV]
validationData  <- validationData[, -NZV]

# remove variables that are mostly NA
mostlyNA <- sapply(trainData, function(x) mean(is.na(x))) > 0.95
trainData <- trainData[, mostlyNA == FALSE]
validationData <- validationData[, mostlyNA == FALSE]

# remove first 7 variables (time series or non-numeric data)
trainData <- trainData[, -c(1:7)]
validationData <- validationData[, -c(1:7)]

# determine data variables that will be used to fit models
dataVariables <- names(trainData[, 1:(length(trainData)-1)])
```

After cleaning, the models will be fit using the following
`r length(dataVariables)` variables:

```{r show-model-variables, echo = FALSE}
dataVariables
```

### Partition the Data

Knowing that we will be predicting the "classe" variable as the indicator of the
training outcome, partition the training dataset (`trainData`) into two sets:
60% of the training data for the modeling process and the remaining 40% for the
test set. This will be performed using random subsampling without replacement.
Cross-validation within the training set will be used to improve model fit
followed by an out-of-sample test with the test set.

```{r partition-data, echo = TRUE}
set.seed(666700)
inTrain  <- createDataPartition(trainData$classe, p = 0.6, list = FALSE)
trainSet <- trainData[inTrain, ]
testSet  <- trainData[-inTrain, ]
```

The `validationData` test dataset will only be used for the "Course Project
Prediction Quiz Portion" of this assignment and thus will remain unchanged.

## Exploratory Data Analysis

The 6 young and healthy participants were asked to perform one set of 10
repetitions of the *Unilateral Dumbbell Biceps Curl* in the following 5
different fashions:

* Class A: exactly according to the specification
* Class B: throwing the elbows to the front
* Class C: lifting the dumbbell only halfway
* Class D: lowering the dumbbell only halfway
* Class E: throwing the hips to the front

This is the "classe" variable in the training set and is used as an indicator
of the training outcome. Class A corresponds to the specified execution of the
exercise, while the other 4 classes correspond to common mistakes.

The following plot shows the distribution of the classe variable in the training
set.

```{r dist-classe-var-training-set, echo = TRUE}
g <- ggplot(trainSet, aes(classe))
g <- g + geom_bar(fill = rgb(0.2, 0.4, 0.6, 0.8))
g <- g + xlab("Classe Level")
g <- g + ylab("Frequency")
g <- g + theme(plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
               axis.text.x = element_text(hjust = 0.5, vjust = 0.5),
               axis.text.y = element_text(hjust = 0.5, vjust = 0.5))
g <- g + ggtitle("Distribution of the Classe Variable in the Training Set")
print(g)
```

## Prediction Model Building

The following three modeling algorithms will be used in this analysis to
determine which one provides the best out-of-sample accuracy:

* Decision Trees
* Random Forests
* Generalized Boosted Model

At the end of each analysis, a confusion matrix will be shown to better
visualize the accuracy of the predictions.

After applying each model to the test set, the model with the highest accuracy
will be used for the prediction quiz portion of the assignment.

### Decision Trees

*Pending*

### Random Forests

*Pending*

### Generalized Boosted Model

*Pending*

## Conclusion

*Pending*


